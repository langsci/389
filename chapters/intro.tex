\documentclass[output=paper,colorlinks,citecolor=brown]{langscibook}
\ChapterDOI{10.5281/zenodo.12090430}
\author{Maria Polinsky\orcid{0000-0003-1460-5089}\affiliation{University of Maryland, College Park} and Michael T. Putnam\orcid{0000-0002-7758-8266}\affiliation{Penn State University; University of Greenwich (CREL)} and Joe Salmons\orcid{}\affiliation{University of Wisconsin – Madison}}
\title{Linguistic complexity in heritage languages: An introduction}
\abstract{\noabstract}
\IfFileExists{../localcommands.tex}{
  \addbibresource{../localbibliography.bib}
  \input{../localpackages}
  \input{../localcommands} 
  \input{../localhyphenation} 
  \togglepaper[1]%%chapternumber
}{}

\begin{document}
\maketitle 
%\shorttitlerunninghead{}%%use this for an abridged title in the page headers

\noindent “I know it when I see it.” Justice Potter Stewart’s famous 1964 sentence referred to a much more exciting phenomenon than the one addressed in this volume \citep{Gewirtz1996}, but it is probably the best distillation of the way complexity in language has been approached. Complexity seems easy to observe, but it lacks clearly established parameters, and its definition remains incredibly subjective and variable. Things only get more complicated (no pun intended) when this notion, however undefined, is used by different researchers to explain sets of language phenomena they observe.\footnote{See \citet{shannon48a,shannon48b} on information theory, and keep in mind the inclusion of measures of entropy and surprisal in linguistic research  (e.g., \citealt{Levy2008}). We will not comment further on these more general treatments of complexity as defined and measured in terms of information theory.} In particular, complexity often emerges as a prominent explanation in work on language acquisition, bilingualism, and language change. What all these research domains have in common is that they take and compare two varieties of what is arguably the same language and strive to explain how these varieties differ: adult/child language in L1 acquisition; native\hyp like\slash non-native\hyp like versions in second language acquisition; monolingual\slash bilingual varieties of one and the same language in bilingualism, and finally, two temporal slices of one and the same language in language diachrony. The comparisons generally rely on complexity as an explanatory tool, but that tool itself takes very different shapes in different hands. Indeed, valiant attempts to define complexity have been made by a number of researchers (consider in particular \citealt{Culicover2013,Dahl2004,MiestamoEtAl2008,Trudgill2011}).

We will not be able to resolve these debates here, but this volume seeks a common core in the existing treatments of complexity, and we apply this common core to heritage languages and their speakers, an area where complexity is constantly discussed, if not always in satisfying ways. That is, we focus on issues of bilingualism, and through it, language acquisition and language change. All the instances of bilingualism discussed in this volume fall under the rubric of \textit{unbalanced bilingualism}, where the bilingual’s home language becomes subordinate to the societal language in adulthood. The former are widely referred to as \textit{heritage languages}, and its speakers as \textit{heritage speakers}. A common view of a heritage language relies on two main criteria: it is acquired as an L1 and it is not the dominant language of the larger (national) society (\citealt{Rothman2009,Montrul2016,Polinsky2018,TsehayeEtAl2021}, and references therein). The social context of heritage languages as minority languages is necessary to understanding the limited social domains where heritage languages may be acquired, used, and maintained.~While this volume is not concerned with the social issues of heritage language use, it is important to underscore that the social context is conducive to a variety of terms used to describe such languages as “minority”, “minoritized”, or “non-dominant”.

Focusing on structural properties of heritage languages, several comparisons can be made within a dominant/heritage bilingual dyad (see \citealt{ScontrasPutnam2020} on the importance of the dyads in heritage language research):\footnote{ \textrm{In our illustrative examples, we rely on the ongoing work of the HLVC project: Heritage Language Variation and Change in Toronto: \url{https://ngn.artsci.utoronto.ca/HLVC/0_0_home.php}}}

\begin{enumerate}
  \item[(i)] between the dominant language as spoken by a monolingual and by a heritage speaker (e.g., monolingual Canadian English and Canadian English spoken by a heritage speaker of Korean living in Toronto);
  \item[(ii)] between a heritage language and the corresponding homeland language (e.g., heritage Korean as spoken in Toronto and Korean spoken in Seoul);
  \item[(iii)] between a heritage language and the baseline: the language of input, which is typically the language spoken by the first-generation adult immigrants (e.g., Korean as spoken by 2+ generations of descendants of Korean immigrants and Korean as spoken by the first generation of Korean immigrants all residing in Toronto).
\end{enumerate}

An evaluation of dominant-language varieties (i) lies beyond the scope of this volume, and we will not comment on it here. Comparisons (ii) and (iii) are not always equally possible. Sometimes data on the baseline are simply missing, which makes an investigation along the lines of (iii) impossible. Sometimes there is no homeland, which makes comparisons in (ii) tricky. Consider here the example of many indigenous minority languages whose traditional language variety is no longer spoken (\cites{GrenobleOsipov2023}{Kehayov2017}[Ch. 1]{Polinsky2018}{Sasse1992}, among others), often resulting in populations of receptive bilinguals (\citealt{HolmesPutnam2020,Sherkina-Lieber2015}), or the situation of a dialect that originated in the homeland but is no longer spoken there, such as Pomeranian, an East Low German language now moribund in Europe and North America but spoken actively in Brazil with growing state support \citep{Savedra2020}.

In early heritage language studies, most comparisons were made between a given heritage language and a homeland language ((ii) above), but as the understanding of heritage bilingualism progressed and the empirical base of heritage-language studies grew, comparisons with the baseline or three-way comparisons (homeland/baseline/heritage variety) have grown more common. Most papers in this volume pursue such a line of inquiry, and this is one area where the notion of complexity becomes prominent. 

Some folk perceptions of complexity are easy to dispense with, for example, the idea that some languages are more complex than others -- one habitually hears something like “Hungarian is more complex than English” or “Italian is less complex than German”. These are often reflections of subjective difficulties in learning a second language in adulthood, through structured instruction, and their echoes in research work on complexity are not too loud. Equally obvious is the idea that complexity has to be defined on multiple levels: phonetics and abstract phonological representations, morphology and morphosyntax, semantics, or the lexicon. The number of dialects and registers in a given language may also contribute to complexity. 

While these misconceptions are easy to set aside, another folk view is prominent in work on bilingualism and this one is more insidious: the view of heritage languages as simplified as compared to their traditional baselines. One of the most prevalent conceptions about heritage languages is that they are somehow “simpler” and “less complex” compared with monolingual grammars. Such a view of heritage languages and their speakers can, and does, have detrimental effects on the public perception of heritage bilingualism, pedagogical initiatives and curriculum development, as well as the development and advancement of theoretical and experimental studies of these grammars. This view faces critical scrutiny in the chapters in this volume, which show that changing complexity in heritage languages is often a trade-off between different levels of representation (see especially Laleko and Varatharaj et al., both this volume). 

To advance our understanding of complexity and how it can enhance linguistic analysis, we distinguish between the defining properties of complexity as a phenomenon, diagnostics of complexity, and the ways complexity is modeled, measured or operationalized in language sciences. In what follows, we will discuss these facets of complexity in turn. 

In defining complexity as a phenomenon, researchers distinguish between language-specific complexity and global complexity, best viewed through the lens of information theory (the latter approach is prominent in Varatharaj et al., this volume). Regardless of whether complexity is defined internally to language or globally, one can further distinguish between complexity in the signal (form) and in the content of the signal (meaning). On the signal plane, it is common to consider those entities more complex that include more constituent parts, but the moment such an approach is assumed, implicitly or explicitly, the question arises as to what counts as a unit and a constituent. To make things somewhat more precise, many approaches to complexity distinguish between abstract (grammatical) atoms, rules that relate such atoms to units of form, and rules that relate such atoms to units of meaning. Distributed Morphology (see \citealt{HarleyNoyer1999,McGinnis-Archibald2016} for overviews) and Nanosyntax \citep{Caha2009} are good examples of models that address these aspects of complexity as a purely linguistic phenomenon, and in this volume, Lohndal and Putnam is an example of such an approach (see also \citealt{LohndalPutnam2021,lohnput24}).

Assuming a division of labor between abstract units, rules, exponents, and interface conditions, the main finding concerning bilingual systems has to do with a reduction or contraction of those domains where interface conditions are applied, where prime examples have to do with the interface between syntax and discourse (see \citealt{Laleko2021} for an overview) and the reduction or regularization in the actual inventory of exponents (e.g. in the constantly discussed reduction of case and other morphological marking). If this approach to complexity is on the right track, then it behooves us to distinguish between units of computation, rules of computation, and interfaces. As is commonly noted, changes occur primarily at the interfaces and in the reduction of computational domains, whereas the abstract units and the rules operating on them remain stable regardless of language contact.  

A related approach in some sense is \citeauthor{Culicover2013}’s proposal for two kinds of complexity. The first, \textit{formal complexity}, is “the measure of the amount of idiosyncrasy in a grammar” and the second, \textit{processing complexity}, is “a measure of the resources required to compute the correspondences between particular grammatical forms and their meanings” (\citeyear[3]{Culicover2013}). Current theorizing no longer treats these two forms of complexity in isolation, allowing us to envisage a path forward where learning to parse (roughly) equates to acquiring and fine-tuning abstract structure. Although the question of which form of complexity comes first and guides the other remains a matter of intense debate (cf. \citealt{ChristiansenChater2016,Lightfoot2020}), scholars on both sides see the benefit of involving both \textit{formal} and \textit{processing complexity} in linguistic analysis.

Decomposing complexity and looking for its properties at the local or global level remains a rather uncommon strategy. A more common approach to complexity is to look for its telltale signs, and in that regard, one finds parallels between research on complexity in bilingual systems and in child language acquisition. Common measures of complexity include frequency differences, with less frequent items or phenomena associated with greater complexity. For example, it is often assumed that passive-voice constructions are more complex than their active counterparts, or that closed syllables are more complex than CV structures. But connecting frequency and complexity creates a circle of a kind: are structures more complex because they are less frequent, or are they less frequent because they are complex? Since the causal relation is unclear, one can use frequency as a possible diagnostic of complexity but not as an explanation of what can be complex. 

Cross-linguistic distribution is another way of diagnosing complexity, the idea being that more complex structures have more restricted distributions. If something is cross-linguistically common, such commonality is often associated with naturalness -- another vague but widely used notion. Both cross-linguistic frequency and naturalness are often used in studies of sound systems, where natural sound patterns are grounded in physical properties of speech, while unnatural sound patterns arguably have no such physical basis (cf. \citealt{Blevins2004,Blevins2007}). The use of cross-linguistic distribution as a metric of complexity and naturalness in sound systems has been valuable, but it is less clear how to apply similar criteria beyond phonetics; once the connection to physical properties of speech is removed, the evaluation metric becomes less clear.

Naturalness and cross-linguistic distribution are also associated with ease of acquisition, and with that a connection between complexity and L1 learning. The age or order of acquisition is also associated with greater complexity; for example, in the L1 acquisition of tone in Mandarin, T3 (also known as the dip(ping) tone) is acquired later than T1, T2, or T4 (\citealt{LiThompson1977}). Likewise, this tone is particularly challenging to L2 learners and heritage speakers of Mandarin (\citealt{ChanChang2019}). Unlike the other tones, this one can be decomposed into fall and subsequent rise, thus being arguably more complex than the other tones. 

It is a common assumption that the three signs of complexity discussed here align: less frequent structures take longer to acquire and may be less common cross-linguistically. Things are actually more nuanced, and we would like to offer several considerations. First, the correlations between frequency, age of acquisition, and cross-linguistic distribution are not iron-clad. Some phenomena that are cross-linguistically rare are unproblematic in acquisition. Subject-verb inversion in English questions is an example (see \citealt{GrinsteadEtAl2018}); such inversion is typologically uncommon, but its acquisition goes without a hitch because the inversion is tied to the fundamental notion of finiteness. Second, the connection between frequency and acquisition is predicated on the idea that acquisition is based on lots of data which then generalize on the basis of similarity. On such a view, abstract knowledge comes after a process of data collection and statistical compression. But there is also the alternative view according to which abstract knowledge guides the use of input and shapes the form of grammatical knowledge throughout development (e.g., \citealt{Lidz2018}). In this view, the patterns of data that children use to acquire grammar differ from the actual structures responsible for those patterns, and in acquiring a language, statistical information in the environment is used for inference but not for building the representations. Next, the cross-linguistic distribution of patterns is the weakest of this set of complexity diagnostics, as our understanding of what is and is not common across languages depends on the extent of our empirical knowledge (after all there are over seven thousand languages and we know about just a small fraction of that sample) as well as social, political or demographic factors of language distribution. 

A related and perhaps equally difficult notion is “markedness”, with appeal to similar criteria and tests, including that unmarked features are more “prototypical” (see \citealt{Haspelmath2006} on the multiple, at times contradictory, understandings of this notion). \citet[1]{Battistella1990} defines \textit{marked} and \textit{unmarked} this way: in terms of polar oppositions in language “the simpler, more general pole is the unmarked term of the opposition while the more complex and focused pole is the marked term”. For instance, Russian /b,d,g/, etc. are specified for or marked as “voiced”, [voice], while /p,t,k/, etc. are unspecified on privative views of phonological features or otherwise “voiceless”, [−voice]. The presence of such a feature is supported by the spread of voicing in clusters, so that \textit{mók} surfaces as [mó\textbf{g} bɨ] `were s/he getting wet' (\citealt[93]{Dresher2009}, example ultimately from \citealt[22]{Halle1971}), as well as its deletion in codas, a prosodically weak position. Many other oppositions do not show obviously simple vs. complex forms, e.g. semantic pairs like \textit{boy/girl}. Battistella is not particularly bothered that “[n]o single diagnostic is a fully reliable indicator” of markedness for any given pair, concluding that “The fact that we cannot define the notions marked and unmarked perfectly is no more surprising than the fact that we cannot define the notion `verb' perfectly” \parencite[45]{Battistella1990}. In their contribution to this volume, D’Alessandro and Terenghi address the connection between markedness and complexity, and propose an important distinction between the two: while markedness is typically assessed with respect to an individual item/language segment, complexity is a more global concept, one that covers a collection of items or language segments. Removing markedness from one of the items in a paradigm may lead to increased complexity elsewhere, hence the recurrent trade-off in complexity across language levels. D’Alessandro and Terenghi’s own proposal, couched in terms of Linguistic Minimalism, relies on the recognition of grammatical features, defined as properties necessary and sufficient to identify grammatical objects or categories (cf. \citealt{AdgerSvenonius2012} on features in Minimalist syntax). 

Let us turn now to the content of the individual contributions, less for a traditional summary of contents than to note what defining properties they deal with, language specific or global, and what diagnostics or model they use. These chapters are different and approach complexity in unique and varied ways, for instance in employing various experimental approaches, ranging from elicited productions to judgment tasks (Kpogo et al., Rinke et al., Laleko), and distinct kinds of cross-linguistic comparisons (Lohndal \& Putnam, Rinke et al., Varatharaj et al., D’Alessandro \& Terenghi).

With an eye on diagnostics of complexity, Felix Kpogo, Alexandra Elizabeth Kohut, and Charles Chang show that second generation Twi speakers in the U.S. prefer a syntactic over a morphological strategy for diminutive formation, in “Expressing diminutive meaning in Twi: The role of complexity and language-specific preferences”. They argue that the morphological strategy is “incrementally” more complex and that the younger generation minimizes that complexity. They see this as a local and not a universal strategy, since it does not appear to match broader diachronic or typological patterns.~

Esther Rinke, Cristina Flores, and Jacopo Torregrossa’s “How different types of complexity can account for difficult structures in bilingual and monolingual language acquisition” also emphasizes diagnostic issues, with attention to age of acquisition. They investigated 180 European heritage speaking-children in Switzerland, which were divided into three different and distinct environmental languages (e.g., French, German, and Italian).  The main contribution of Rinke et al.’s chapter lies in showing that the difficulties encountered by these bilingual children cannot be accounted for in terms of a single notion of complexity. Rather, individual structures and phenomena may be complex in acquisition for different reasons. In particular, Rinke et al. identify four main notions of complexity that are related to the structures they investigate: derivational complexity; memory-based learning; context dependency of rules, and multiple form-function mappings.

In “The complexity of word order change in a flexible system: On stability and variation in heritage Russian word order”, Oksana Laleko points to the need for nuanced diagnostics in assessing complexity. English-dominant heritage speakers of Russian do not show any general move toward English-like SVO structures, nor difficulties with information structure. Instead, they provide evidence for stronger SOV patterns, distinctly unlike English. She characterizes the use of SOV patterns as “a rarely documented case of non-transfer-induced complexity-preserving change”.

\begin{sloppypar}
Terje Lohndal and Michael T. Putnam’s contribution, “Expanding structures while reducing mappings: Morphosyntactic complexity in agglutinating heritage languages”,~emphasizes the importance of agglutinating and polysynthetic languages for more general claims concerning modeling complexity in heritage languages. Building on their previous work (\citealt{LohndalPutnam2021,lohnput24}) and a related architecture developed by \citet{López2020}, Lohndal \& Putnam argue for modeling morphological complexity in heritage languages through the lens of a late-insertion, exoskeletal model of the syntax-morphology interface. A point of emphasis is the tension between lexicalizing larger spans of syntactic structure, while also ``shrinking'' computational domains (see also \citealt{ScontrasEtAl2018} and \citealt{PolinskyScontras2020} for similar arguments). 
\end{sloppypar}

Ashvini Varatharaj, Gregory Scontras, and Naomi Nagy, in “A multi-gen\-er\-a\-tion\-al analysis of heritage language complexity”, emphasize global defining properties across generations of heritage speakers of a half dozen heritage languages in Toronto. They explore possible “complexity trade-offs” between morphological and syntactic complexity over generations. They find some support for a shift from morphological to word-order complexity. This is especially so for Ukrainian speakers, perhaps, they argue, due to the very different morphological systems of English and Ukrainian.

In “Non-monotonic functional sequences: A new metric for complexity in heritage languages”, Roberta D'Alessandro and Silvia Terenghi focus on diagnostics, seeking motivation in language design and thus also framing complexity as a global phenomenon. As hinted at above, complexity in part needs to be reckoned not in terms of exponents but in terms of ‘monotonicity and uniformity’ in computation. Once monotonicity and uniformity are lacking, they argue, that opens the door to language change.

There are clearly common threads running through these papers. For example, Laleko, Kpogo et al., Rinke et al., and Varatharaj et al. all understand complexity as something that has to be considered in terms of a specific level of representation or even construction. Of course, the papers arrive at no consensus beyond the already-familiar (if hardly universally accepted!) understanding that language contact, language change, and bilingualism  --  here specifically under the circumstances of heritage language bilingualism  --  do not lead inevitably to simplification, or even to complexification, but rather can involve “complexity invariance”, to follow Laleko (this volume).

We summarize the proposed set of defining features of complexity in \figref{fig:intro:definition} below. We use the traditional linguistic contrast between form and meaning to capture facets of complexity on the language-specific level, and its more general counterpart, the contrast between signal and content on the global level.

\begin{figure}
    \begin{forest}   
    for tree={grow'=east, forked edges, anchor=west},
    [Complexity
    [{as a\\language-specific\\ phenomenon}
	[in form
	    [features, tier=last]
	    [rules and\\ interface\\ conditions, tier=last]
	]
	[in meaning
	    [{internal\\computation}, tier=last]
	    [{interface\\conditions}, tier=last]
	]
    ]
    [{as an aspect\\ of any system\\ (globally defined)}
	[in the signal
	    [{atomic\\units}, tier=last]
	    [{operations\\ on units}, tier=last]
	]
	[~,no edge]
	[{in the content}]
    ]
    ]
    \end{forest}
\caption{\label{fig:intro:definition} Defining features of complexity}
\end{figure}

Building on the representation in \figref{fig:intro:definition}, while most contributions in this volume define complexity as a global, domain-general phenomenon, Kpogo et al. propose that certain instances of complexity, such as the syntactic (vs. the morphological) formation of diminutives in Twi by second generation heritage speakers, can be viewed as something language-specific under certain conditions. Complexity is clearly present in ambient input according to the studies set forth by Rinke et al. and Varatharaj et al., while Kpogo et al., D’Alessandro and Terenghi, Laleko, and Lohndal and Putnam find complexity in the content of representations. The findings of Varatharaj et al. once again emphasize the importance of typological proximity and distance between the languages existing within a dyad (\citealt{PutnamEtAl2018,ScontrasPutnam2020}). Aside from Kpogo et al., most contributions investigate measures of complexity as they relate to forms (i.e., representations) rather than meaning. D’Alessandro and Terenghi and Lohndal and Putnam conceptualize the notion of complexity in abstract feature rules while also holding to some notion of modularity and interface compatibility. Kpogo et al., Laleko, and Rinke et al.’s contributions emphasize the importance of language-internal restructuring, or internal computation. Varatharaj et al.’s proposal of ‘complexity trade-offs’ straddles this distinction. Laleko’s study combines the requirement of interface conditions and internal computation, resulting in word-order patterns that are distinctly complexity-preserving.

In closing, the diversity of definitions of complexity and their implementations in analysis found in this volume raise more questions than they ultimately resolve. Nonetheless, we interpret the proposals and supporting arguments for various strands of complexity as an exciting opportunity to further engage with this central notion in heritage language bilingualism. We eagerly look forward to seeing where these discussions lead and how they may direct and shape additional studies moving forward.

\section*{Acknowledgments}

The editors would like to thank the authors of these chapters and their reviewers for their work. We would also like to thank the editors of the Language Science Press series \textit{Current Issues in Bilingualism} for making this volume happen. We are grateful to Terje Lohndal, Naomi Nagy, Esther Rinke, and Greg Scontras for comments on the earlier version of this introduction. All errors are our responsibility.

\printbibliography[heading=subbibliography,notkeyword=this]
\end{document} 
